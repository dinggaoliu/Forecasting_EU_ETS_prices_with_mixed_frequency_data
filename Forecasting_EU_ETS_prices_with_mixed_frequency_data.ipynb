{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536f8fd-1b3f-4d64-9b2c-ee3de2405058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss, RMSE, MAPE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205d5d7-4118-4f32-9b5f-e20d3e41453a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # seed init.\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    # torch seed init.\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False # train speed is slower after enabling this opts.\n",
    "\n",
    "    # https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "    # avoiding nondeterministic algorithms (see https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361e7d6-5f66-4fd5-8f5a-090665761173",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('soft_test_predictEPU.csv')\n",
    "#data = data.drop(['EEPU_Yield', 'GEPU_Yield'], axis=1)\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785081a7-e5ce-4c56-82bd-34db0ec3e984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.astype(dict(series=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3c263-2c80-4ff4-af1a-1b1c5b16895b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train, Validation, Test Split\n",
    "n = len(data)\n",
    "training_df = data[0:int(n * 0.8)]\n",
    "validation_df = data[int(n * 0.8):int(n * 0.9)]\n",
    "test_df = data[int(n * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89493e5f-a267-4963-969a-5ad87a48f2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_prediction_length = 1\n",
    "max_encoder_length = 5\n",
    "#training_cutoff = training_df[\"time_idx\"].max() - max_prediction_length*2\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    training_df,\n",
    "    #training_df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Price_Yield\",\n",
    "    group_ids=[\"series\"],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    categorical_encoders={\"series\": NaNLabelEncoder().fit(training_df.series)},\n",
    "    static_categoricals=[\"series\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"Price_Yield\",\n",
    "        \"STOXX600_Yield\",\n",
    "        \"NaturalGas_Yield\",\n",
    "        \"BrentOil_Yield\",\n",
    "        \"Coal_Yield\",\n",
    "        \"Powerload_Yield\",\n",
    "        \"predict_EEPU_Yield\",\n",
    "        \"predict_GEPU_Yield\"\n",
    "        #\"EEPU_Yield\",\n",
    "        #\"GEPU_Yield\"\n",
    "    ],\n",
    "    add_relative_time_idx=True,\n",
    "    #lags={\"Price_Yield\":[1]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175888e2-e9d8-4f2e-af5e-235d4a275409",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(training, validation_df, predict=False, stop_randomization=True)\n",
    "test = TimeSeriesDataSet.from_dataset(training, test_df, predict=False, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)\n",
    "test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd75c2-fdef-4602-9090-d2ee1bf817ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    train_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=10,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val_range=(0.1, 0.1),\n",
    "    hidden_size_range=(8, 256),\n",
    "    hidden_continuous_size_range=(4, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.0001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=64, accelerator=\"cpu\"),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "    \n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2f610-6b71-480b-b6eb-6d9046ce0c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.best_trial.params['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb034b9-0110-433f-9635-4195e7760a5f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=study.best_trial.params['learning_rate'],\n",
    "    hidden_size=study.best_trial.params['hidden_size'],\n",
    "    attention_head_size=study.best_trial.params['attention_head_size'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    hidden_continuous_size=study.best_trial.params['hidden_continuous_size'],\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c3bf5-3e17-4415-9f70-c3a5dbd1f958",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=1e-5, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "#pl.Trainer(deterministic=True)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=64,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    "\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.08,\n",
    "    hidden_size=118,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=30,\n",
    "    loss=QuantileLoss(),\n",
    "    #log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    "\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee3f55-4728-4144-8c2f-fbfd7bf77b80",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef9dcb-3a42-4a9e-bc5b-aca7f07605fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a21fcd-5432-4d4a-9070-9a7701e54383",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = best_tft.predict(val_dataloader, mode=\"prediction\", return_y=True)\n",
    "#predictions = best_tft.predict(test_dataloader, mode=\"prediction\", return_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a76b1-bbb9-4093-98b6-05e1421b47a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predict = np.array(predictions.output.cpu())\n",
    "raw = np.array(predictions.y[0].cpu())\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(predict, label=\"predict\")\n",
    "plt.plot(raw, label=\"raw\")\n",
    "plt.legend();\n",
    "\n",
    "print(len(predict))\n",
    "print(len(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625c933-b1bf-488d-a649-13579e100324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "attentions = best_tft.predict(test_dataloader, mode=\"raw\", return_x=True)\n",
    "interpretation = best_tft.interpret_output(attentions.output, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
